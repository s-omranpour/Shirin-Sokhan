{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6477d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    ")\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9214c3e0",
   "metadata": {},
   "source": [
    "## tokenizer and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10893bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"HooshvareLab/gpt2-fa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    \"bos_token\": '</s>',\n",
    "    \"eos_token\": '</s>', \n",
    "    \"pad_token\": '<pad>',\n",
    "    \"unk_token\": '<unk>',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56ef3e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11643882"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.data\n",
    "reload(src.data)\n",
    "from src.data import PoemDataset, get_dataloaders\n",
    "\n",
    "dataset = PoemDataset(tokenizer, 'data/all_poems.json', window=512)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd28cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset has 10421668 samples and val dataset has 1157963 samples\n"
     ]
    }
   ],
   "source": [
    "tl, vl = get_dataloaders(dataset, val_frac=0.1, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00667bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([4, 167])\n",
      "attention_mask torch.Size([4, 167])\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(tl))\n",
    "for k in b:\n",
    "    print(k, b[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46511bb",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "387b45ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: GPT2-fa-ganjoor-conditional\n"
     ]
    }
   ],
   "source": [
    "import src.model\n",
    "reload(src.model)\n",
    "from src.model import PoetFormer\n",
    "\n",
    "name = 'GPT2-fa-ganjoor-conditional'\n",
    "print('model name:',name)\n",
    "\n",
    "model = PoetFormer(pretrained_name=\"HooshvareLab/gpt2-fa\")\n",
    "model.load_pretrained()\n",
    "\n",
    "# model = PoetFormer.load_from_checkpoint(f'weights/{name}/last.ckpt', pretrained=\"HooshvareLab/gpt2-fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48865c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118099200"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab700f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "127a5b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "logger = TensorBoardLogger(save_dir='logs/', name=name)\n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=f'weights/{name}/', \n",
    "    filename='{epoch}-{val_loss:.2f}', \n",
    "    monitor='val_loss',\n",
    "    save_top_k=1, \n",
    "    period=1\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    benchmark=True, \n",
    "    gpus=1, \n",
    "    accumulate_grad_batches=1,\n",
    "    logger=logger, \n",
    "    max_epochs=1,\n",
    "    callbacks=[checkpoint, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3864cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 118 M \n",
      "------------------------------------------\n",
      "118 M     Trainable params\n",
      "0         Non-trainable params\n",
      "118 M     Total params\n",
      "472.397   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa6560e791a4e2198fa1c977a42cf4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7cd82d0af0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/soroosh/projects/general_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1203, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/soroosh/projects/general_env/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1177, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 318, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 360, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 300, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 195, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1011, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/usr/lib/python3.8/threading.py\", line 1027, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa65101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(f'weights/{name}/last.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94831b8d",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebc073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import PoetFormer\n",
    "\n",
    "name = 'GPT2-fa-ganjoor-conditional'\n",
    "print('model name:',name)\n",
    "\n",
    "# model = PoetFormer(pretrained=\"HooshvareLab/gpt2-fa\")\n",
    "model = PoetFormer.load_from_checkpoint(f'weights/{name}/last.ckpt', pretrained=\"HooshvareLab/gpt2-fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0151fc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating poem in \"حافظ\" style.\n",
      "حافظ:\n",
      "به دست می‌دهد این زلف و زلف و می‌گویم\n",
      "که خوب‌تر شوم یا نه من و نه من مپرس\n",
      "مرض ز مشک تو و مشک ز مشک تو و مشک تو\n",
      "بی‌خبر ز تو و بی‌جهالستیم\n",
      "مرا بباید اندر جهان همی‌شنیم\n",
      "جفا به کشتن من ای ملامتگر\n",
      "که کس ندانست قدر ترا که می‌باید\n",
      "جفا به کشتن من نیز بی‌تو بر تنم\n",
      "برآ به زاری من ای جفاگر و بی‌تو\n",
      "مرا به زاری و زاری ز بهر درد تو\n",
      "به عشق تو گرفتار بدن شدم\n"
     ]
    }
   ],
   "source": [
    "res = model.generate(prompt='', num_return_sequences=1, max_length=128, n_beam=1)\n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c898f98c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
