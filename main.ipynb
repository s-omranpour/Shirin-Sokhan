{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6477d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/metrics/__init__.py:43: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5\n",
      "  rank_zero_deprecation(\n",
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    ")\n",
    "\n",
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9214c3e0",
   "metadata": {},
   "source": [
    "## tokenizer and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10893bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"HooshvareLab/gpt2-fa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(name)\n",
    "\n",
    "tokenizer.add_special_tokens({\n",
    "    \"bos_token\": '</s>',\n",
    "    \"eos_token\": '</s>', \n",
    "    \"pad_token\": '<pad>',\n",
    "    \"unk_token\": '<unk>',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56ef3e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11579631"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import src.data\n",
    "reload(src.data)\n",
    "from src.data import PoemDataset, get_dataloaders\n",
    "\n",
    "dataset = PoemDataset(tokenizer, 'data/all_poems.json', max_len=512)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd28cb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset has 10421668 samples and val dataset has 1157963 samples\n"
     ]
    }
   ],
   "source": [
    "tl, vl = get_dataloaders(dataset, val_frac=0.1, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00667bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([5, 177])\n",
      "attention_mask torch.Size([5, 177])\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(tl))\n",
    "for k in b:\n",
    "    print(k, b[k].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46511bb",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "387b45ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pretrained model: HooshvareLab/gpt2-fa\n"
     ]
    }
   ],
   "source": [
    "import src.model\n",
    "reload(src.model)\n",
    "from src.model import PoetFormer\n",
    "\n",
    "model = PoetFormer(pretrained=\"HooshvareLab/gpt2-fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48865c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118099200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.count_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e92dcabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "حافظ:\n",
      "وی «ان» هم که از این کلمه‌ها در ادبیات ما استفاده شده، این کلمه‌ها، به شکل «ان» هستند. حال، یک سوال مطرح می‌شود که چطور می‌توانیم این کلمات را در کلماتمان جای دهیم؟ این سوال، یکی از مسائل بسیار مهم در علم منطق است. «ان» در لغت به معنی «بودن» است و در واقع همان «بودن» است. «ان» در زبان فارسی به معنای «بودن» است و «بودن» به معنی «بودن» است. پس «بودن» یعنی «بودن». برای پاسخ به این سوال، فرض کنید می‌\n"
     ]
    }
   ],
   "source": [
    "res = model.generate(num_return_sequences=1, max_length=128, n_beam=1)\n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fab700f",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "127a5b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soroosh/projects/general_env/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:396: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_val_epochs` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: GPT2-fa-ganjoor-conditional\n"
     ]
    }
   ],
   "source": [
    "name = 'GPT2-fa-ganjoor-conditional'\n",
    "print('model name:',name)\n",
    "\n",
    "logger = TensorBoardLogger(save_dir='logs/', name=name)\n",
    "lr_logger = LearningRateMonitor(logging_interval='step')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    dirpath=f'weights/{name}/', \n",
    "    filename='{epoch}-{val_loss:.2f}', \n",
    "    monitor='val_loss',\n",
    "    save_top_k=1, \n",
    "    period=1\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    benchmark=True, \n",
    "    gpus=1, \n",
    "    accumulate_grad_batches=1,\n",
    "    logger=logger, \n",
    "    max_epochs=1,\n",
    "    callbacks=[checkpoint, lr_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864cae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params\n",
      "------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 118 M \n",
      "------------------------------------------\n",
      "118 M     Trainable params\n",
      "0         Non-trainable params\n",
      "118 M     Total params\n",
      "472.397   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8daeebc2c0e84974bc5946b2f3e60b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, tl, vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa65101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(f'weights/{name}/last.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd3b35",
   "metadata": {},
   "source": [
    "## generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd676a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.generate(num_return_sequences=1, max_length=128, n_beam=1)\n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255baa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
